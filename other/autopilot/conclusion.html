<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type" />

    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="" />
    <meta name="author" content="Alexey Shrub aka worldmind" />
    <link rel="icon" href="../../favicon.ico" />

<title>Вывод</title>

<link href="what_do.html" title="Что делать роботу" rel="prev" />
<link href="index.html" title="Существуют ли моральные проблемы при разработке автопилота?" rel="up" />

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous" />

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>
<body>

<div class="container">

<div class="navigation">
<span>Previous: <a href="what_do.html">Что делать роботу</a></span>
<span> Up: <a href="index.html">Существуют ли моральные проблемы при разработке автопилота?</a></span>
<span> <a href="/">Home</a></span>

</div>

<div><h1 id="conclusion">9 Вывод</h1>
<ol class="enumerate">
<li><p>Раз мораль не универсальна/субъективна, то автопилоту надо переключать настройки морального выбора в зависимости от пассажира (а их надо с него как-то считывать). А если пассажиров несколько с разными моральными профилями, чей выбирать? </p></li><li><p>Реалистичных примеров ситуаций с моральным выбором пока не придумали, а значит затруднительно запрограммировать автопилот на распознавание таких ситуаций. У нас есть критерии понятные человеку, а не машине. </p></li><li><p>Для принятия морального решения нужно знать результат этого решения т.е. знать будущее, а оно не известно. </p></li><li><p>Автопилот это программа, он не имеет модели ситуации аналогичной человеческой, а значит не может принимать решения как это сделал бы человек. Моральные решения это задача разума, а не программ. </p></li><li><p>Робот должен соблюдать правила и действовать предсказуемо. </p></li><li><p>Робот не должен жертвовать пассажиром. </p></li>
</ol><p> Похоже ни о каком моральном выборе при разработке автопилота говорить не имеет смысла. </p></div>





<div class="navigation">
<span>Previous: <a href="what_do.html">Что делать роботу</a></span>
<span> Up: <a href="index.html">Существуют ли моральные проблемы при разработке автопилота?</a></span>
<span> <a href="/">Home</a></span>

</div>

</body>
</html>
